### KUTUPHANELER (START) ###
import streamlit as st
import pandas as pd  # Veri analizi ve DataFrame islemleri icin kullanilir
import numpy as np  # Sayisal islemler ve array yapilari icin kullanilir
import matplotlib.pyplot as plt  # Grafik cizimi ve gorsellestirme icin kullanilir
import seaborn as sns  # Gelismis istatistiksel grafikler icin kullanilir

from sklearn.preprocessing import StandardScaler # veriyi standartlastirmak icin kullanilir

# Model Egitimi Icin #
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score 
# train_test_split: veriyi egitim ve test olarak bolmek icin kullanilir  
# GridSearchCV: en iyi model parametrelerini bulmak icin grid arama yapar (cross-validation icerir)
# cross_val_score: Modeller uzerinde cross-validation uygulamamizi saglar

from sklearn.preprocessing import LabelEncoder, StandardScaler  
# LabelEncoder: kategorik etiketleri sayisal degerlere donusturmek icin kullanilir  
# StandardScaler: veriyi ortalama=0, std=1 olacak sekilde standartlastirir (normalize eder)


from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay  
# accuracy_score: dogruluk oranini hesaplar  
# confusion_matrix: gercek vs tahmin siniflarin karsilastirmasini tablo olarak verir  
# classification_report: precision, recall, f1-score gibi siniflandirma metriklerini verir
# ConfusionMatrixDisplay: Grafiksel karmasiklik Matriksi

import tensorflow as tf  # TensorFlow kÃ¼tÃ¼phanesi

import altair as alt # Bar grafigi icin kullanilir
### KUTUPHANELER (END) ###

### AYARLAR (START) ##
# Ortak veri yÃ¼kleme
@st.cache_data
def load_data(path):
    return pd.read_csv(path)
data = load_data("data.csv")
### AYARLAR (END) ###

### FONKSIYONLAR (START) ###
## tasarim foknsiyonlari ##

#Bilgi kutucugu
def boxInfo(content: str, border_color: str = "#ADD8E6"):
    st.markdown(f"""
    <div style='background-color: #f9f9f9; padding: 15px 15px 5px 15px; border-left: 5px solid {border_color}; border-radius: 5px'>
        {content}
    </div>
    """, unsafe_allow_html=True)

#Acikleme Kutucu
def boxExp(content: str, border_color: str = "#ADD8E6"):
    st.markdown(f"""
    <div style='background-color: #f9f9f9; padding: 15px 15px 5px 15px; border-top: 5px solid {border_color}; border-radius: 5px'>
        {content}
    </div>
    """, unsafe_allow_html=True)
## ./tasarim foknsiyonlari ##
### FONKSIYONLAR (END) ###

def app():

    # Ana iÃ§erik
    st.title("Veri Analizi & Ã–n Ä°ÅŸleme")

    
    boxExp("""
    **Veri Analizi**, verilerin iÃ§indeki anlamlÄ± desenleri, eÄŸilimleri ve iliÅŸkileri keÅŸfetmek iÃ§in yapÄ±lan sistematik incelemedir. AmaÃ§, karar verme sÃ¼reÃ§lerini desteklemek iÃ§in veriden bilgi Ã§Ä±karmaktÄ±r.

    **Ã–n Ä°ÅŸleme** ise, verilerin analiz veya modelleme iÃ§in uygun hale getirilmesi sÃ¼recidir. Eksik verilerin doldurulmasÄ±, aykÄ±rÄ± deÄŸerlerin temizlenmesi, verinin standardize edilmesi gibi adÄ±mlarÄ± iÃ§erir.

    Bu adÄ±mlar, bir makine Ã¶ÄŸrenmesi modelinin baÅŸarÄ±sÄ±nÄ± doÄŸrudan etkileyen temel hazÄ±rlÄ±k sÃ¼recidir.
    """, "black")
    
    st.header("Ä°lk BakÄ±ÅŸ")
    col1, col2 = st.columns(2) # 2 adet sutun olsuturmak icin
    
    with col1:
        st.subheader("SÃ¼tun Ä°simleri")
        
        df_columns = pd.DataFrame(data.columns, columns=["SÃ¼tun AdÄ±"]) # Orijinal veri kÃ¼mesinin sÃ¼tun adlarÄ±nÄ± yeni bir DataFrameâ€™e aktarÄ±r
        df_columns.index = df_columns.index + 1 # Ä°ndeks numaralarÄ±nÄ± 1â€™den baÅŸlatÄ±r (varsayÄ±lan 0â€™dan 1â€™e)
        st.dataframe(df_columns, use_container_width=True) # SÃ¼tun adlarÄ± tablosunu geniÅŸ konteyner iÃ§inde gÃ¶sterir

    with col2:
        st.subheader("Ä°lk 10 KayÄ±t")  # BÃ¶lÃ¼m baÅŸlÄ±ÄŸÄ±
        st.dataframe(data.head(10), use_container_width=True)  # data.head(10) Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶sterir

        st.write(f"SatÄ±r sayÄ±sÄ±: {data.shape[0]}, SÃ¼tun sayÄ±sÄ±: {data.shape[1]}")

    st.write('---')

    ## Eksik Veri Adimi ##
    st.header("Eksik Veri KontrolÃ¼")

    boxInfo("""
    **Eksik Veri (Missing Data)**: Veri setinde bazÄ± hÃ¼crelerin boÅŸ kalmasÄ± durumudur.

    **Neden KaldÄ±rÄ±lÄ±r?**  
    Eksik veriler, analiz ve model performansÄ±nÄ± olumsuz etkileyebilir. Bu yÃ¼zden Ã§oÄŸu zaman ya silinir ya da uygun deÄŸerlerle doldurulur.
    """)
    
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Ä°ÅŸlem Ã–ncesi SÃ¼tun Listesi")
        st.write(data.isnull().sum().sort_values(ascending=False))  # data.isnull().sum() Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶sterir.
        # .sort_values(ascending=False) ile buyukten kucuge bir siralama yapildi.

        # Model iÃ§in anlamsÄ±z olan 'id' sÃ¼tununu kaldÄ±rÄ±r
        data.drop("id", axis=1, inplace=True)  # 'id' sÃ¼tunu kaldÄ±rÄ±ldÄ±

        # TÃ¼m deÄŸerleri eksik olan 'Unnamed: 32' sÃ¼tununu kaldÄ±rÄ±r
        data.drop("Unnamed: 32", axis=1, inplace=True)  # 'Unnamed: 32' sÃ¼tunu kaldÄ±rÄ±ldÄ±

    with col2:
        # GÃ¼ncel sÃ¼tun adlarÄ±nÄ± gÃ¶stermek istersen
        st.subheader("Ä°ÅŸlem SonrasÄ± SÃ¼tun Listesi")
        st.dataframe(pd.DataFrame(data.columns, columns=["SÃ¼tun AdÄ±"]), use_container_width=True)

        
    boxInfo("""
    **Ne YaptÄ±m?** 
    <br>Veri setini Kaggle.com Ã¼zerinden indirdiÄŸimde, '***Unnamed: 32***' adÄ±nda tamamen boÅŸ bir sÃ¼tun ve model eÄŸitimi iÃ§in anlamlÄ± bir bilgi taÅŸÄ±mayan '***id***' adlÄ± bir sÃ¼tun olduÄŸunu fark ettim. Eksik veri analizi sÄ±rasÄ±nda bu sÃ¼tunlarÄ± tespit ederek veri setinden Ã§Ä±kardÄ±m.

    """, "green")


    
    ## ./Eksik Veri Adimi ##

    st.write('---')

    ## Genel Analiz Adimi ##
    st.header("Genel Analiz AdÄ±mÄ±")

    boxInfo("""
    Bu yapÄ±larÄ±, veri setini modelleme Ã¶ncesinde daha iyi anlayabilmek iÃ§in oluÅŸturdum.

    - **Diagnosis daÄŸÄ±lÄ±m grafiÄŸi** ile hedef deÄŸiÅŸkenin sÄ±nÄ±f dengesini gÃ¶rselleÅŸtirdim.  
    - **TanÄ±mlayÄ±cÄ± istatistikler tablosu** ile sayÄ±sal deÄŸiÅŸkenlerin temel istatistiksel Ã¶zelliklerini inceledim.

    Bu sayede verinin genel yapÄ±sÄ±nÄ± Ã¶zetleyerek sonraki adÄ±mlara hazÄ±r hale getirdim.
    """)


    col1, col2 = st.columns(2)

    with col1:
        # figÃ¼r boyutunu 6x4 inÃ§ olarak ayarladÄ±k
        fig, ax = plt.subplots(figsize=(3, 2))

        st.subheader("Hedef DeÄŸiÅŸkenler")
        sns.countplot(
            x="diagnosis",
            hue="diagnosis",
            data=data,
            palette={"M": "red", "B": "green"},
            ax=ax
        )  # renk ayrÄ±mÄ±: M iÃ§in kÄ±rmÄ±zÄ±, B iÃ§in yeÅŸil

        ax.set_title("Diagnosis DaÄŸÄ±lÄ±mÄ±")   # grafik baÅŸlÄ±ÄŸÄ±
        ax.set_xlabel("TeÅŸhis TÃ¼rÃ¼")         # X ekseni etiketi
        ax.set_ylabel("SayÄ±")                # Y ekseni etiketi
        st.pyplot(fig, use_container_width=False)

    with col2:
        # TanÄ±mlayÄ±cÄ± Ä°statistikler: sayÄ±sal sÃ¼tunlar iÃ§in ortalama, std, min, max vb. bilgileri gÃ¶sterir
        st.subheader("TanÄ±mlayÄ±cÄ± Ä°statistikler")
        desc = data.describe()                  # describe() ile temel istatistiksel bilgileri alÄ±r
        st.dataframe(desc, use_container_width=True)  # istatistikleri tablo halinde gÃ¶sterir
    ## ./Genel Analiz Adimi ##

    st.write('---')

    ## Ortlama ve Standart Sapma Kontrol Adimi ##
    st.header("Ortalama ve Standart Sapma Kontrol AdÄ±mÄ±")

    boxInfo("""
    **Ortalama (Mean)**: Verilerin genel merkezini temsil eder. TÃ¼m deÄŸerlerin toplamÄ±nÄ±n, veri sayÄ±sÄ±na bÃ¶lÃ¼nmesiyle elde edilir.  

    **Standart Sapma (Std)**: Verilerin ortalama etrafÄ±nda ne kadar yayÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir. Yani, deÄŸerlerin ortalamadan ne kadar sapma gÃ¶sterdiÄŸini ifade eder.

    Bu deÄŸerlere bakarak veri setindeki daÄŸÄ±lÄ±mÄ± gÃ¶zlemliyorum. BÃ¶ylece deÄŸiÅŸkenler arasÄ±nda Ã¶lÃ§ek farkÄ± olup olmadÄ±ÄŸÄ±nÄ± anlayÄ±p uygun bir ***Ã¶lÃ§eklendirme yÃ¶ntemi*** belirleyeceÄŸim.
    """)
    st.write("")

    st.subheader("Ortalama KontrolÃ¼")

    col1, col2 = st.columns(2)
    with col1:
        # TanÄ±mlayÄ±cÄ± istatistiklerden ortalamalarÄ± alÄ±yoruz ve bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe sÄ±ralÄ±yoruz
        means = desc.loc["mean"].sort_values(ascending=False)  # tÃ¼m sÃ¼tunlarÄ±n ortalama deÄŸerlerini alÄ±r

        # Ortalama deÄŸerleri tablo halinde gÃ¶steriyoruz
        st.dataframe(means.to_frame(name="Ortalama DeÄŸer"), use_container_width=True)  # means serisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p gÃ¶sterir

    with col2:
        # Ã‡ubuk grafik ile ortalamalarÄ± gÃ¶rselleÅŸtiriyoruz
        fig, ax = plt.subplots(figsize=(6, 4), dpi=100)     # figÃ¼r boyutunu ve dpi'Ä± ayarlar
        means.plot(kind="bar", ax=ax)                       # bar plot Ã§izer
        ax.set_title("Ã–zelliklerin Ortalama DeÄŸerleri")     # grafik baÅŸlÄ±ÄŸÄ±
        ax.set_ylabel("Ortalama DeÄŸer")                     # Y ekseni etiketi
        ax.set_xlabel("")                                   # X ekseni etiketi (boÅŸ bÄ±rakÄ±labilir)
        ax.tick_params(axis="x", rotation=90)               # X etiketlerini dikeyden yataya dÃ¶ndÃ¼rÃ¼r
        ax.grid(axis="y")                                   # Y eksenine grid ekler
        plt.tight_layout()                                  # dÃ¼zeni sÄ±kÄ±ÅŸtÄ±rarak taÅŸmalarÄ± engeller

        # GrafiÄŸi Streamlit ana alanÄ±na ekler; container geniÅŸliÄŸini kullanmaz
        st.pyplot(fig, use_container_width=False)

    # Standart Sapma
    st.subheader("Standart Sapma KontrolÃ¼")

    col1, col2 = st.columns(2)

    with col1:
        # Sadece sayÄ±sal sÃ¼tunlarÄ± al (diagnosis gibi kategorik sÃ¼tunlarÄ± Ã§Ä±kar)
        numeric_df = data.select_dtypes(include="number")
        
        # Her sÃ¼tunun standart sapmasÄ±nÄ± hesapla
        std_table = numeric_df.std().sort_values(ascending=False).to_frame("Standart Sapma")
        std_table.index.name = "Ã–zellik"
        
        # Streamlitâ€™te tabloyu gÃ¶ster
        st.dataframe(std_table)

    with col2:
        # Grafik oluÅŸturma
        fig, ax = plt.subplots(figsize=(8, 6))
        desc.loc["std"].sort_values().plot(kind="barh", ax=ax)
        ax.set_title("Ã–zelliklerin Standart SapmalarÄ±")
        ax.set_xlabel("Standart Sapma")
        plt.tight_layout()

        # GrafiÄŸi Streamlitâ€™e ekle
        st.pyplot(fig, use_container_width=False)


    boxInfo("""
    Ortalama ve standart sapma deÄŸerlerine baktÄ±ÄŸÄ±mda, bazÄ± Ã¶zelliklerin (Ã¶zellikle **area_worst** ve **area_mean**) diÄŸerlerine kÄ±yasla Ã§ok daha yÃ¼ksek deÄŸerlere ve varyansa sahip olduÄŸunu fark ettim.  
    Bu durum, model eÄŸitiminde bu Ã¶zelliklerin aÅŸÄ±rÄ± aÄŸÄ±rlÄ±k kazanmasÄ±na ve dengesiz kararlara yol aÃ§abileceÄŸini gÃ¶steriyor.  
    Bu nedenle tÃ¼m Ã¶zellikleri ortak bir Ã¶lÃ§eÄŸe Ã§ekmek iÃ§in ***StandardScaler*** ile standartlaÅŸtÄ±rma yapmaya karar verdim.
    """, "green")

    st.write("")
    st.write("")
    
# Ã–zellik Ã–lÃ§eklendirme AdÄ±mÄ±
    st.subheader("Ã–zellik Ã–lÃ§eklendirme AdÄ±mÄ± (StandartScaler)")
    boxInfo("""
    **StandardScaler Nedir?**  
    Scikit-learn kÃ¼tÃ¼phanesinin bir Ã¶n iÅŸleme aracÄ±dÄ±r.

    **NasÄ±l Ã‡alÄ±ÅŸÄ±r?**  
    - EÄŸitim verisindeki her Ã¶zelliÄŸin ortalamasÄ± (Î¼) hesaplanÄ±r.  
    - Her deÄŸerden bu ortalama Ã§Ä±kartÄ±lÄ±r: ğ‘¥â€² = ğ‘¥ âˆ’ Î¼  
    - Ortalamadan arÄ±ndÄ±rÄ±lan deÄŸer, ilgili Ã¶zelliÄŸin standart sapmasÄ±na (Ïƒ) bÃ¶lÃ¼nÃ¼r: ğ‘¥â€³ = ğ‘¥â€² / Ïƒ  
    - SonuÃ§ta tÃ¼m Ã¶zellikler ortalama=0 ve standart sapma=1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  

    **KaynakÃ§a:**  
    Scikit-learn Developers. (2024). *StandardScaler*. Scikit-learn documentation. <br>
    EriÅŸim: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
    """)

    st.write("")

    # Ã–lÃ§eklendirme Ã¶ncesi ve sonrasÄ± tablolarÄ±nÄ± yan yana gÃ¶stermek iÃ§in iki sÃ¼tun oluÅŸturuyoruz
    oncesi, sonrasi = st.columns(2)

    with oncesi:
        st.subheader("**Ã–lÃ§eklendirme Ã–ncesi (ilk 5 satÄ±r)**")  # bÃ¶lÃ¼m baÅŸlÄ±ÄŸÄ±
        st.dataframe(
            data.drop("diagnosis", axis=1).head(5),              # teÅŸhis sÃ¼tunu hariÃ§ orijinal veri
            use_container_width=True
        )

    # Scaler nesnesi oluÅŸturulur ve uygulanÄ±r
    scaler = StandardScaler()                                   # ortalama=0, std=1 Ã¶lÃ§eklendirme yapacak
    scaled_values = scaler.fit_transform(data.drop("diagnosis", axis=1))  
    data_scaled = pd.DataFrame(                                  # Ã¶lÃ§eklenmiÅŸ DataFrame oluÅŸturma
        scaled_values,
        columns=data.columns.drop("diagnosis")
    )
    data_scaled["diagnosis"] = data["diagnosis"].values         # hedef sÃ¼tunu geri ekleme

    with sonrasi:
        st.subheader("**Ã–lÃ§eklendirme SonrasÄ± (ilk 5 satÄ±r)**")  # bÃ¶lÃ¼m baÅŸlÄ±ÄŸÄ±
        st.dataframe(
            data_scaled.drop("diagnosis", axis=1).head(5),      # Ã¶lÃ§eklenmiÅŸ veri
            use_container_width=True
        )


    boxInfo("""
    **StandardScalerâ€™i neden uyguladÄ±m?**  
    Verideki Ã¶zellikler Ã§ok farklÄ± Ã¶lÃ§eklere sahipti (Ã¶rneÄŸin `area_mean` binlerce, `smoothness_se` ise kÃ¼Ã§Ã¼k ondalÄ±k deÄŸerler).  
    Bu Ã¶lÃ§ek farkÄ±, modelin bazÄ± Ã¶zelliklere aÅŸÄ±rÄ± aÄŸÄ±rlÄ±k vermesine yol aÃ§abilirdi.  
    Bu yÃ¼zden tÃ¼m Ã¶zellikleri ortalama=0, sapma=1 olacak ÅŸekilde standartlaÅŸtÄ±rdÄ±m. BÃ¶ylece:
    - **Ã–zelliklerin eÅŸit katkÄ±sÄ±nÄ±** saÄŸladÄ±m.  
    - **YakÄ±nsama sÃ¼resini** hÄ±zlandÄ±rarak eÄŸitim sÃ¼recini kararlÄ± kÄ±ldÄ±m.  
    - SVM, KNN gibi **mesafeye dayalÄ± algoritmalarÄ±n** performansÄ±nÄ± artÄ±rdÄ±m.  
    - AÅŸÄ±rÄ± bÃ¼yÃ¼k deÄŸerlerin yol aÃ§abileceÄŸi **sayÄ±sal kararsÄ±zlÄ±klarÄ±** Ã¶nledim.  
    - Modelimin **genelleÅŸtirme yeteneÄŸini** gÃ¼Ã§lendirdim.
    """, "green")
        ## ./Ortlama ve Standart Sapma Kontrol Adimi ##

    st.write('---')
    
    ## AykÄ±rÄ± Deger Adimi ##
    st.header("AykÄ±rÄ± DeÄŸer AdÄ±mÄ±")

    boxInfo("""
    **AykÄ±rÄ± DeÄŸerlere Boxplot & IQR ile Bakma YÃ¶ntemim**  
    Verideki uÃ§ deÄŸerleri gÃ¶rsel olarak tespit etmek iÃ§in boxplot grafiÄŸi kullanacaÄŸÄ±m.  
    Boxplotâ€™ta kutunun alt Ã§eyreÄŸi (Q1) ile Ã¼st Ã§eyreÄŸi (Q3) arasÄ±ndaki mesafe, yani **IQR (Ã‡eyrekler ArasÄ± AralÄ±k)** Ã¼zerinden Ã§alÄ±ÅŸÄ±yorum.  

    - **IQR HesabÄ±:**  
    IQR = Qâ‚ƒ âˆ’ Qâ‚  

    - **AykÄ±rÄ± DeÄŸer Kriteri:**  
    â€¢ Alt sÄ±nÄ±r = Qâ‚ âˆ’ 1.5 Ã— IQR  
    â€¢ Ãœst sÄ±nÄ±r = Qâ‚ƒ + 1.5 Ã— IQR  

    Bu sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±nda kalan gÃ¶zlemleri potansiyel aykÄ±rÄ± deÄŸer olarak iÅŸaretleyip inceleyeceÄŸim.

    **KaynakÃ§a:**  
    Tukey, J. W. (1977). *Exploratory Data Analysis*. Addison-Wesley.   
    """)

    # Boxplot figÃ¼rÃ¼ oluÅŸturulur (Ã¶lÃ§eklenmiÅŸ veri, 'diagnosis' hariÃ§)
    fig, ax = plt.subplots(figsize=(8, 4))  # figÃ¼r boyutu: 8x4 inÃ§
    sns.boxplot(
        data=data_scaled.drop("diagnosis", axis=1),  # hedef sÃ¼tunu Ã§Ä±kar
        orient="h",                                   # yatay orientasyon
        ax=ax
    )
    ax.set_title("AykÄ±rÄ± DeÄŸerlerin Boxplot ile GÃ¶sterimi (Scaled Veri)")  # grafik baÅŸlÄ±ÄŸÄ±
    plt.tight_layout()  # dÃ¼zen sÄ±kÄ±ÅŸtÄ±rma

    # GrafiÄŸi Streamlit ana alanÄ±na ekle; konteyner geniÅŸliÄŸini kullanma
    st.pyplot(fig, use_container_width=False)


    boxInfo("""
    <b>Ne YaptÄ±m?</b><br>
    Veri setinde Ã§ok sayÄ±da aykÄ±rÄ± deÄŸer tespit ettim. TÄ±p alanÄ±ndaki veri setlerinde uÃ§ deÄŸerlerin bulunmasÄ± sÄ±k rastlanan bir durum ve bu deÄŸerler klinik Ã§eÅŸitliliÄŸi, nadir vakalarÄ± yansÄ±tÄ±r.  
    Bu aykÄ±rÄ± deÄŸerlerin model eÄŸitimi iÃ§in Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mden, silmek yerine modelin bu uÃ§ Ã¶rneklerden Ã¶ÄŸrenmesini saÄŸlayarak daha gerÃ§ekÃ§i ve genelleyici sonuÃ§lar elde etmeyi tercih ettim.
    """, "green")
    ## ./AykÄ±rÄ± Deger Adimi ##

    

    st.write('---')

    ## ./Korelasyon Adimi ##
    # Korelasyon AdÄ±mÄ± ve Ã–zellik SeÃ§imi
    st.header("Korelasyon AdÄ±mÄ± ve Ã–zellik SeÃ§imi")

    boxInfo("""
    **Korelasyon Nedir?**  
    Korelasyon, iki sayÄ±sal deÄŸiÅŸken arasÄ±ndaki doÄŸrusal iliÅŸkinin yÃ¶nÃ¼nÃ¼ ve gÃ¼cÃ¼nÃ¼ Ã¶lÃ§mek demek. DeÄŸerler -1 ile 1 arasÄ±nda deÄŸiÅŸir; 1 tam pozitif, -1 tam negatif iliÅŸkiyi gÃ¶sterir.  

    **Neden Korelasyona BakÄ±yorum?**  
    Veri setimde birbirine Ã§ok benzeyen (yÃ¼ksek korelasyonlu) Ã¶zellikler modelde redundant bilgiye ve multicollinearityâ€™ye yol aÃ§abilir. Hangi deÄŸiÅŸkenlerin birbirine fazlaca baÄŸlÄ± olduÄŸunu gÃ¶rÃ¼p gereksiz olanlarÄ± elemek iÃ§in korelasyon analizini kullanÄ±yorum.
    """)

    # SayÄ±sal sÃ¼tunlarÄ± seÃ§
    x = data_scaled.select_dtypes(include=['float64', 'int64'])

    # FigÃ¼r ve eksen oluÅŸtur, boyutunu ayarla
    fig, ax = plt.subplots(figsize=(16, 8))

    # Heatmapâ€™i Ã§iz
    sns.heatmap(
        x.corr(),
        annot=True,
        linewidths=0.5,
        fmt='.1f',
        ax=ax
    )
    ax.set_title("Korelasyon HaritasÄ±")

    # Streamlitâ€™e doÄŸru figÃ¼rÃ¼ ekle
    st.pyplot(fig, use_container_width=True)

    # SayÄ±sal sÃ¼tunlarÄ± seÃ§
    x = data_scaled.select_dtypes(include=['float64', 'int64'])

    # Korelasyon matrisini mutlak deÄŸer olarak al
    corr_matrix = x.corr().abs()

    # Ãœst Ã¼Ã§geni (i<j) al
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

    # Korelasyonu 0.95'ten bÃ¼yÃ¼k olan Ã§iftleri yakala
    high_pairs = (
        upper
        .stack()                             # Ã‡ok seviyeli index serisi: (Feature A, Feature B) -> corr
        .reset_index(name='r')               # DataFrameâ€™e Ã§evir
        .rename(columns={'level_0':'Feature A','level_1':'Feature B'})
    )

    # Sadece r>0.95 Ã§iftleri al, istersen sÄ±ralayabilirsin
    high_pairs = high_pairs[high_pairs['r'] > 0.95].sort_values('r', ascending=False)

    # Streamlitâ€™te gÃ¶ster
    st.markdown("### r > 0.95 korelasyona sahip Ã§iftler")
    st.dataframe(high_pairs, use_container_width=True)
    
    boxInfo("""
    <b>Ne YaptÄ±m?</b><br>
    Tabloya gÃ¶re **r > 0.95** korelasyona sahip Ã¶zellik Ã§iftlerinden her grupta bir temsilci Ã¶zellik seÃ§ip diÄŸerini kaldÄ±racaÄŸÄ±m. Ancak bu sÃ¼reÃ§te Ã§ok dikkatli olmam gerekiyor: **0.95** Ã¼stÃ¼ korelasyon bile birÃ§ok sÃ¼tun arasÄ±nda yaygÄ±n. YanlÄ±ÅŸ bir Ã¶zellik silimi, modelin doÄŸruluÄŸunu olumsuz etkileyebilir.  
    Bu nedenle her adÄ±mÄ± titizlikle inceleyerek, model performansÄ±nÄ± koruyacak ÅŸekilde seÃ§im yapmalÄ±yÄ±m.
    """, "green")

    ## ./Korelasyon Adimi ##

    st.write('---')

    ## Hedef Degisken Adimi ##
    st.subheader("Hedef DeÄŸiÅŸken AdÄ±mÄ±")

    # Orijinal (B/M) sÄ±nÄ±flarÄ± korumak iÃ§in veri kÃ¼mesinin bir kopyasÄ±nÄ± alÄ±yoruz
    data_unmapped = data.copy()

    # EÄŸer diagnosis hÃ¢lÃ¢ string ise, B=1, M=0 ÅŸeklinde sayÄ±sala dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz
    if data_scaled["diagnosis"].dtype == object:
        data_scaled["diagnosis"] = data_scaled["diagnosis"].map({"B": 1, "M": 0})

    # KullanÄ±cÄ±ya neden bu dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yaptÄ±ÄŸÄ±mÄ±zÄ± aÃ§Ä±klÄ±yoruz
    boxInfo("""
    **Neden â€˜diagnosisâ€™ Etiketlerini SayÄ±sallaÅŸtÄ±rdÄ±m?**  
    Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n yalnÄ±zca sayÄ±sal girdilerle Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± bildiÄŸim iÃ§in, sÄ±nÄ±flandÄ±rma hedefim olan â€˜diagnosisâ€™ sÃ¼tunundaki kategorik etiketleri dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼m.  
    - â€œBâ€ (Benign) deÄŸerini **1**,  
    - â€œMâ€ (Malign) deÄŸerini **0**  

    olarak kodladÄ±m. Bu sayede modelim, hedef deÄŸiÅŸkeni doÄŸrudan iÅŸleyebildi ve performansÄ±nÄ± artÄ±rdÄ±m.  
    """)

    # Orijinal ve dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ sÄ±nÄ±f daÄŸÄ±lÄ±mlarÄ±nÄ± yan yana gÃ¶steriyoruz
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # 1) Orijinal (B/M) daÄŸÄ±lÄ±m
    sns.countplot(
        x="diagnosis",
        hue="diagnosis",
        data=data_unmapped,
        ax=axes[0],
        palette="Set2",
        legend=False
    )
    axes[0].set_title("Orijinal SÄ±nÄ±flar (B/M)")
    axes[0].set_xlabel("SÄ±nÄ±f")
    axes[0].set_ylabel("Adet")

    # 2) DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ (1/0) daÄŸÄ±lÄ±m
    sns.countplot(
        x="diagnosis",
        hue="diagnosis",
        data=data_scaled,
        ax=axes[1],
        palette="Set1",
        legend=False
    )
    axes[1].set_title("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ SÄ±nÄ±flar (B=1, M=0)")
    axes[1].set_xlabel("SÄ±nÄ±f")
    axes[1].set_ylabel("Adet")

    plt.tight_layout()

    # GrafiÄŸi Streamlit ana alanÄ±na ekliyoruz
    st.pyplot(fig, use_container_width=True)

    ## ./Hedef Degisken Adimi ##
    st.write("---")
    st.header("SonuÃ§")
    boxInfo("""
    Veri analizi ve Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± tamamladÄ±m:  
    - **Eksik veri** kontrolÃ¼ ve gereksiz sÃ¼tunlarÄ±n temizlenmesi  
    - **Ortalama** ve **standart sapma** analizleri  
    - **AykÄ±rÄ± deÄŸer** tespiti ve uygun yaklaÅŸÄ±mla korunmasÄ±  
    - **Korelasyon** incelemesi ve yÃ¼ksek iliÅŸkili Ã¶zelliklerin elenmesi  

    ArtÄ±k elde ettiÄŸim bu temiz ve dengelenmiÅŸ veri setiyle, hem geleneksel makine Ã¶ÄŸrenme modelleri hem de derin Ã¶ÄŸrenme modelleri Ã¼zerinde test ve deÄŸerlendirmelerime geÃ§eceÄŸim.
    """, "green")

    # En son elde ettigimiz veri setini kaydetmemiz gerekiyor.
    st.session_state["data_scaled"] = data_scaled


        